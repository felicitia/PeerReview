{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openreview' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-153f255c5028>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mopenreview\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mclient\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenreview\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mClient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbaseurl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'https://api.openreview.net'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0musername\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'yixuezhao@cs.umass.edu'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpassword\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'7uQ@3t3Nwe2h6ZQ'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mnotes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenreview\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterget_notes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minvitation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'ICLR.cc/2019/Conference/-/Blind_Submission'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# for note in notes:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'openreview' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "import openreview\n",
    "\n",
    "client = openreview.Client(baseurl='https://api.openreview.net', username='yixuezhao@cs.umass.edu', password='7uQ@3t3Nwe2h6ZQ')\n",
    "notes = openreview.tools.iterget_notes(client, invitation='ICLR.cc/2019/Conference/-/Blind_Submission')\n",
    "# for note in notes:\n",
    "#     print(note)\n",
    "#     break\n",
    "all_decision_notes = openreview.tools.iterget_notes(client, invitation = 'MIDL.io/2019/Conference/-/Paper.*/Decision')\n",
    "results = client.search_profiles(first='Andrew', last='McCallum')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "0.5224 \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT? \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n",
      "0.5084 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n",
      "0.5035 \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting. \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.\n",
      "0.4660 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT?\n",
      "0.3620 \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting. \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT?\n",
      "0.3445 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.\n",
      "0.3146 \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor. \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "0.2635 \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable. \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "0.2582 \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor. \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "0.2179 \n",
      " Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor. \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.\n",
      "0.2168 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "0.2091 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting.\n",
      "0.1899 \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting. \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "0.1732 \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting. \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.\n",
      "0.1707 \n",
      " You also say that VAT helps maintain local smoothness so as to prevent overfitting. \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "0.1375 \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper. \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "0.1143 \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT? \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.\n",
      "0.1032 \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT? \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "0.1024 \n",
      " In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper. \n",
      " Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.\n",
      "0.0952 \n",
      " When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting. \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n",
      "0.0861 \n",
      " Then shouldn’t you also be comparing against JointVAE + VAT? \n",
      " There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "sentences = ['When comparing against JointVAE, the authors point out that the accuracy for JointVAE is worse than that of IMAE, a sign of overfitting.',\n",
    "          'You also say that VAT helps maintain local smoothness so as to prevent overfitting.',\n",
    "          'Then shouldn’t you also be comparing against JointVAE + VAT?',\n",
    "          'Looking at Appendix D, it seems like VAT makes a big difference in terms of I(y;y_true), so I’m guessing it will also have a big impact on the accuracy.'\n",
    "          'Thus JointVAE + VAT might beat IMAE in terms of accuracy as well, at which point it will be hard to argue that IMAE is superior in learning the discrete factor.',\n",
    "          'In the first paragraph of Section 4, the authors claim results on CelebA, but these are missing from the paper.', #2\n",
    "          'Testing the approach on datasets more complex than (Fashion)Mnist would have been desirable.', #2\n",
    "          'There aren’t any latent traversals for the discrete latents - this would be a useful visualisation to complement the accuracy plots in Figure 3.'\n",
    "          # 'Furthermore, the scope of the study is too narrow to draw general conclusions (e.g., number of recommendations studied in total, number of techniques studied in total, types of caching recommendations studied).',\n",
    "          # 'Finally, the results are not promising and I’m not sure how beneficial the current state of the work is to our community. The paper does point out 7 future directions but they are at a high level without supporting evidence, which is not directly useful to future work, showing a lack of depth.',\n",
    "          # 'I would suggest showing *concrete* evidence on at least one direction that can indeed improve cache recommendations by implementing an “updated” technique that outperforms the 2 existing work in your study.',\n",
    "          # 'I believe this is valuable work, but the current state of the work is too premature to be published at TSE. I recommend Revise and Resubmit as “new”.',\n",
    "          # 'See my detailed comments for suggestions on further improvement.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations:\n",
    "    print(\"{:.4f} \\n {} \\n {}\".format(cos_sim[i][j], sentences[i], sentences[j]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens ['Lambda', 'is', 'overloaded', '(', 'context', 'distribution', 'vs.', 'regularization', 'hyper', '-', 'parameter', ')', '.']\n",
      "POS ['PROPN', 'AUX', 'ADJ', 'PUNCT', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'PUNCT']\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'num_tokens': 13,\n 'counts': Counter({'context distribution': 1,\n          'context distribution vs. regularization': 1,\n          'context distribution vs. regularization hyper': 1,\n          'context distribution vs. regularization hyper -': 1,\n          'context distribution vs. regularization hyper - parameter': 1,\n          'distribution vs. regularization': 1,\n          'distribution vs. regularization hyper': 1,\n          'distribution vs. regularization hyper -': 1,\n          'distribution vs. regularization hyper - parameter': 1,\n          'regularization hyper': 1,\n          'regularization hyper -': 1,\n          'regularization hyper - parameter': 1,\n          'hyper -': 1,\n          'hyper - parameter': 1,\n          '- parameter': 1})}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import phrasemachine\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Lambda is overloaded (context distribution vs. regularization hyper-parameter).\")\n",
    "tokens = [token.text for token in doc]\n",
    "pos = [token.pos_ for token in doc]\n",
    "print('tokens', tokens)\n",
    "print('POS', pos)\n",
    "phrasemachine.get_phrases(tokens=tokens, postags=pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}