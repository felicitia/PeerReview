{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled Disentangling of GANs with Guided Siamese Networks\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Unlabeled Disentangling of GANs with Guided Siamese Networks\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Unlabeled Disentangling of GANs with Guided Siamese Networks\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Unlabeled Disentangling of GANs with Guided Siamese Networks\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Heated-Up Softmax Embedding\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Heated-Up Softmax Embedding\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Heated-Up Softmax Embedding\n",
      "PRO 2 [[['+'], ['The', 'idea', 'of', 'heating', 'up', 'the', 'temperature', 'in', 'softmax', 'is', 'interesting', ',', 'and', 'seems', 'novel', 'in', 'the', 'literature', 'of', 'metric', 'learning', '.']], [['+'], ['The', 'performance', 'improvement', ',', 'especially', 'produced', 'by', 'batchNorm', '-', 'based', 'normalization', ',', 'is', 'shown', '.']]]\n",
      "CON 4 [[['-'], ['The', 'formulation', 'of', 'tempered', 'softmax', 'with', 'normalization', 'is', 'already', 'presented', 'in', '[', 'Wang', 'et', 'al.', ',', '2017', ']', '.']], [['-'], ['The', 'reason', 'why', 'the', 'heating', '-', 'up', 'approach', 'contributes', 'to', 'better', 'metric', 'learning', 'is', 'not', 'clearly', 'provided', 'in', 'a', 'well', 'convincing', 'way', '.']], [['-'], ['It', 'lacks', 'an', 'important', 'ablation', 'study', 'to', 'fairly', 'validate', 'the', 'method', '.']], [['-'], ['The', 'discussion', '/', 'comparison', 'is', 'limited', 'to', 'the', 'simple', 'softmax', 'function', '.']]]\n",
      "INFORMATION MAXIMIZATION AUTO-ENCODING\n",
      "PRO 3 [[['-'], ['The', 'derivation', 'of', 'the', 'loss', 'shows', 'a', 'nice', 'link', 'between', 'Mutual', 'information', 'and', 'total', 'correlation', 'in', 'the', 'latents', '.']], [['-'], ['It', 'is', 'a', 'sensible', 'idea', 'to', 'treat', 'the', 'MI', 'terms', 'of', 'the', 'discrete', 'latents', 'differently', 'to', 'the', 'continuous', 'latents']], [['-'], ['The', 'mathematical', 'and', 'quantitative', 'analysis', 'of', 'MI', 'and', 'its', 'relation', 'to', 'decoder', 'means', 'and', 'variances', 'are', 'informative', '.']]]\n",
      "CON 5 [[['-', 'There', 'is', 'not', 'enough', 'quantitative', 'comparison', 'of', 'the', 'quality', 'of', 'disentanglement', 'across', 'the', 'different', 'methods', '.'], ['The', 'only', 'values', 'for', 'this', 'are', 'the', 'accuracy', 'scores', 'of', 'the', 'discrete', 'factor', ',', 'but', 'for', 'the', 'continuous', 'latents', 'there', 'are', 'only', 'qualitative', 'latent', 'traversals', 'of', 'single', 'models', ',', 'and', 'I', 'think', 'these', 'are', 'n’t', 'enough', 'for', 'comparing', 'different', 'disentangling', 'methods', '-', 'this', 'is', 'too', 'prone', 'to', 'cherry', '-', 'picking', '.'], ['I', 'think', 'it', '’s', 'definitely', 'necessary', 'to', 'report', 'some', 'metrics', 'for', 'disentangling', 'that', 'are', 'averaged', 'across', 'multiple', 'models', 'trained', 'with', 'different', 'random', 'seeds', '.'], ['I', 'understand', 'that', 'there', 'are', 'no', 'ground', 'truth', 'cts', 'factors', 'for', 'Mnist', '/', 'FashionMnist', ',', 'but', 'this', 'makes', 'me', 'think', 'that', 'a', 'dataset', 'such', 'as', 'dSprites', '(', 'aka', '2D', 'Shapes', ')', 'where', 'the', 'factors', 'are', 'known', 'and', 'has', 'a', 'mix', 'of', 'discrete', 'and', 'continuous', 'factors', 'would', 'have', 'been', 'more', 'suitable', '.'], ['Here', 'you', 'can', 'use', 'various', 'metrics', 'proposed', 'in', 'Eastwood', 'et', 'al', ',', 'Kim', 'et', 'al', ',', 'Chen', 'et', 'al', 'for', 'a', 'quantitative', 'comparison', 'of', 'the', 'disentangled', 'representations', '.']], [['-'], ['In', 'figure', '4', ',', 'it', 'says', 'beta=lamda=5', 'for', 'all', 'models', '.'], ['Should', 'n’t', 'you', 'be', 'doing', 'a', 'hyperparameter', 'sweep', 'for', 'each', 'model', 'and', 'choose', 'the', 'best', 'value', 'of', 'hyperparameters', 'for', 'each', '?'], ['It', 'could', 'well', 'be', 'that', 'beta=5', 'works', 'best', 'for', 'IMAE', 'but', 'other', 'values', 'of', 'beta', '/', 'lambda', 'can', 'work', 'better', 'for', 'the', 'other', 'models', '.']], [['-', 'When', 'comparing', 'against', 'JointVAE', ',', 'the', 'authors', 'point', 'out', 'that', 'the', 'accuracy', 'for', 'JointVAE', 'is', 'worse', 'than', 'that', 'of', 'IMAE', ',', 'a', 'sign', 'of', 'overfitting', '.'], ['You', 'also', 'say', 'that', 'VAT', 'helps', 'maintain', 'local', 'smoothness', 'so', 'as', 'to', 'prevent', 'overfitting', '.'], ['Then', 'should', 'n’t', 'you', 'also', 'be', 'comparing', 'against', 'JointVAE', '+', 'VAT', '?'], ['Looking', 'at', 'Appendix', 'D', ',', 'it', 'seems', 'like', 'VAT', 'makes', 'a', 'big', 'difference', 'in', 'terms', 'of', 'I', '(', 'y', ';y_true', ')', ',', 'so', 'I', '’m', 'guessing', 'it', 'will', 'also', 'have', 'a', 'big', 'impact', 'on', 'the', 'accuracy', '.'], ['Thus', 'JointVAE', '+', 'VAT', 'might', 'beat', 'IMAE', 'in', 'terms', 'of', 'accuracy', 'as', 'well', ',', 'at', 'which', 'point', 'it', 'will', 'be', 'hard', 'to', 'argue', 'that', 'IMAE', 'is', 'superior', 'in', 'learning', 'the', 'discrete', 'factor', '.']], [['-'], ['In', 'the', 'first', 'paragraph', 'of', 'Section', '4', ',', 'the', 'authors', 'claim', 'results', 'on', 'CelebA', ',', 'but', 'these', 'are', 'missing', 'from', 'the', 'paper', '.'], ['Testing', 'the', 'approach', 'on', 'datasets', 'more', 'complex', 'than', '(', 'Fashion', ')', 'Mnist', 'would', 'have', 'been', 'desirable', '.']], [['-', 'There', 'are', 'n’t', 'any', 'latent', 'traversals', 'for', 'the', 'discrete', 'latents', '-', 'this', 'would', 'be', 'a', 'useful', 'visualisation', 'to', 'complement', 'the', 'accuracy', 'plots', 'in', 'Figure', '3.']]]\n",
      "INFORMATION MAXIMIZATION AUTO-ENCODING\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "INFORMATION MAXIMIZATION AUTO-ENCODING\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "I Know the Feeling: Learning to Converse with Empathy\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "I Know the Feeling: Learning to Converse with Empathy\n",
      "PRO 5 [[['A', 'lot', 'of', 'good', 'thoughts', 'were', 'put', 'into', 'the', 'work', ',', 'and', 'even', 'though', 'the', 'techniques']], [['tried', 'are', 'relatively', 'unsophisticated', ',', 'the', 'work', 'represents', 'a', 'serious', 'attempt']], [['on', 'the', 'subject', 'and', 'is', 'of', 'good', 'reference', 'value', '.']], [['The', 'linkage', 'between', 'the', 'use', 'of', 'emotion', 'supervision', 'and', 'better', 'relevancy', 'is', 'interesting', '.']], [['The', 'dataset', 'by', 'itself', 'is', 'a', 'good', 'contribution', 'to', 'the', 'community', 'conducting', 'studies', 'in', 'this', 'area', '.']]]\n",
      "CON 7 [[['The', 'conclusions', 'are', 'somewhat', 'fuzzy', 'as', 'there', 'are', 'too', 'many', 'effects']], [['interacting', ',', 'and', 'as', 'a', 'result', 'no', 'clear', 'cut', 'recommendations', 'can', 'be', 'made']], [['(', 'perhaps', 'with', 'the', 'exception', 'that', 'ensembling', 'a', 'classifier', 'model', 'trained']], [['for', 'emotion', 'recognition', 'together', 'with', 'the', 'response', 'selector', 'is', 'seen']], [['as', 'having', 'advantages', ')', '.']], [['There', 'are', 'some', 'detailed', 'questions', 'that', 'are', 'unaddressed', 'or', 'unclear', 'from']], [['the', 'writing', '.'], ['See', 'the', 'Misc.', 'items', 'below', '.']]]\n",
      "I Know the Feeling: Learning to Converse with Empathy\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile\n",
      "PRO 1 [[['This', 'paper', 'provides', 'an', 'optimistic', 'mirror', 'descent', 'algorithm', 'to', 'solving', 'minmax', 'optimization', 'problem', '.'], ['Its', 'global', 'convergence', 'is', 'guaranteed', 'under', 'the', 'coherence', 'property', '.'], ['The', 'experimental', 'results', 'are', 'promising', '.']]]\n",
      "CON 3 [[['1', '.'], ['The', 'coherence', 'property', 'is', 'still', 'a', 'strong', 'assumption', '.'], ['The', 'sufficient', 'conditions', 'provided', 'in', 'Corollary', '3.2', 'and', '3.3', 'to', 'guarantee', 'coherence', 'property', 'are', 'too', 'specific', 'to', 'cover', 'existing', 'GAN', 'models', '.']], [['2', '.'], ['The', 'current', 'theoretical', 'contribution', 'seems', 'incrementally', '.'], ['From', 'the', 'perspective', 'of', 'operator', 'theory', ',', 'the', 'coherence', 'property', 'is', 'highly', 'related', 'to', 'the', 'pseudo-', 'monotone', 'property', '.'], ['Extragradient', 'method', 'to', 'solve', 'the', 'pseudo-monotone', 'VIP', 'has', 'already', 'existed', 'in', 'the', 'literature', '[', '1', ']', '.'], ['The', 'proposed', 'OMD', 'can', 'be', 'simply', 'regarded', 'a', 'stochastic', 'extension', 'of', '[', '1', ']', 'and', 'simultaneously', 'generalize', 'the', 'European', 'distance', 'in', '[', '1', ']', 'to', 'Bregman', 'distance', '.']], [['3', '.'], ['The', 'integrating', 'of', 'Adam', 'and', 'OMD', 'in', 'the', 'experiments', 'is', 'very', 'interesting', '.'], ['To', 'match', 'the', 'experiments', ',', 'we', 'highly', 'recommend', 'the', 'authors', 'to', 'show', 'the', 'convergence', 'of', 'OMD', '+', 'Adam', 'with', 'or', 'without', 'coherence', 'condition', ',', 'rather', 'than', 'requiring', 'a', 'diminishing', 'learning', 'rate', '.']]]\n",
      "Why do deep convolutional networks generalize so poorly to small image transformations?\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Why do deep convolutional networks generalize so poorly to small image transformations?\n",
      "PRO 0 []\n",
      "CON 0 []\n",
      "Why do deep convolutional networks generalize so poorly to small image transformations?\n",
      "PRO 0 []\n",
      "CON 0 []\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_file = '../../iclr-discourse-dataset/review_rebuttal_pair_dataset_debug/traindev_train_clean.json'\n",
    "with open(input_file) as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "all_pairs = data['review_rebuttal_pairs']\n",
    "# print(all_pairs[0].keys()) # output: dict_keys(['index', 'review_sid', 'rebuttal_sid', 'review_text', 'rebuttal_text', 'title', 'review_author', 'forum', 'labels'])\n",
    "\n",
    "example_reviews = []\n",
    "for current_pair in all_pairs:\n",
    "    # if current_pair['forum'] == 'H1e0-30qKm':\n",
    "    current_review = {}\n",
    "    current_review['review_text'] = current_pair['review_text']\n",
    "    current_review['title'] = current_pair['title']\n",
    "    current_review['review_author'] = current_pair['review_author']\n",
    "    current_review['forum'] = current_pair['forum']\n",
    "    current_review['labels'] = current_pair['labels']\n",
    "    current_review['pros'] = []\n",
    "    current_review['cons'] = []\n",
    "    # current_review['minor'] = [] # other minor points, e.g., refs, typos\n",
    "    example_reviews.append(current_review)\n",
    "    # print(current_pair['index'], current_pair['forum'], current_pair['title'])\n",
    "\n",
    "for review in example_reviews:\n",
    "    review_text = review['review_text']\n",
    "    for paragraph_index, paragraph in enumerate(review_text):\n",
    "        if is_special_paragraph(paragraph):\n",
    "            process_paragraph(paragraph, paragraph_index, review_text, review)\n",
    "    print(review['title'])\n",
    "    print('PRO', len(review['pros']), review['pros'])\n",
    "    print('CON', len(review['cons']), review['cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "word_in_sentence_cutoff = 5 # minimal number of words that a regular sentence should have, in order to exclude special paragraphs, e.g., formatting like '=====', headings like 'Summary:'\n",
    "\n",
    "# paragraph contains one sentence with less than word_in_sentence_cutoff words\n",
    "# start with '[', e.g., [1] citation\n",
    "# end with ':'\n",
    "def is_special_paragraph(paragraph):\n",
    "    if len(paragraph) == 1 and len(paragraph[0]) < word_in_sentence_cutoff or paragraph[0][0] == '[' or paragraph[len(paragraph)-1][len(paragraph[len(paragraph)-1])-1] == ':':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_paragraph(paragraph, paragraph_index, review_text, review):\n",
    "    if len(paragraph[0]) < word_in_sentence_cutoff:\n",
    "        first_word = paragraph[0][0]\n",
    "        if re.match('pro', first_word, re.I):\n",
    "            # print(review['title'])\n",
    "            paragraph_index += 1\n",
    "            bullet = review_text[paragraph_index][0][0]\n",
    "            if re.match('[a-z]', bullet, re.I):\n",
    "                # add each paragraph as a point\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if not is_special_paragraph(review_text[index]):\n",
    "                        review['pros'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of pros\n",
    "            elif re.match('[0-9]', bullet):\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if re.match('[0-9]', review_text[index][0][0]):\n",
    "                        review['pros'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of pros\n",
    "            else:\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if review_text[index][0][0] == bullet:\n",
    "                        review['pros'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of pros\n",
    "\n",
    "        if re.match('con', first_word, re.I):\n",
    "            # print(review['title'])\n",
    "            paragraph_index += 1\n",
    "            bullet = review_text[paragraph_index][0][0]\n",
    "            if re.match('[a-z]', bullet, re.I):\n",
    "                # add each paragraph as a point\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if not is_special_paragraph(review_text[index]):\n",
    "                        review['cons'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of cons\n",
    "            elif re.match('[0-9]', bullet):\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if re.match('[0-9]', review_text[index][0][0]):\n",
    "                        review['cons'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of cons\n",
    "            else:\n",
    "                for index in range(paragraph_index, len(review_text)):\n",
    "                    if review_text[index][0][0] == bullet:\n",
    "                        review['cons'].append(review_text[index])\n",
    "                    else:\n",
    "                        break # if the bullet changes, it's the end of cons\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}